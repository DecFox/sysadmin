# Managed by ansible; see roles/ooni-measurements/templates/ngx-oomsm-web

{% import 'common.j2' as c %}

# Use 2-level cache, 20MB of RAM + 5GB on disk,
proxy_cache_path /var/cache/nginx-api levels=1:2 keys_zone=apicache:100M
                max_size=5g inactive=24h use_temp_path=off;

# moderate throttling applied globally
limit_req_zone $binary_remote_addr zone=limit_qps:60m rate=120r/m;
limit_req_log_level info;

# anonymize ipaddr
map $remote_addr $remote_addr_anon {
  ~(?P<ip>\d+\.\d+\.\d+)\.    $ip.0;
  ~(?P<ip>[^:]+:[^:]+):       $ip::;
  default                     0.0.0.0;
}

# log anonymized ipaddr and caching status
log_format apilogfmt '$remote_addr_anon $upstream_cache_status [$time_local] '
    '"$request" $status $body_bytes_sent "$http_referer" "$http_user_agent"';

server {
    listen 80;
    listen 443 ssl http2;

    keepalive_timeout 120 120; # http://kb.mozillazine.org/Network.http.keep-alive.timeout

    {{ c.ssl_letsencrypt(ssl_domain) }}

    server_name api.ooni.io {{ ssl_domain }};

    access_log  /var/log/nginx/{{ ssl_domain }}.access.log apilogfmt;
    #access_log syslog:server=unix:/dev/log combined;
    error_log   /var/log/nginx/{{ ssl_domain }}.error.log warn;

    proxy_read_timeout {{ oomsm_timeout_s }}s;

    limit_req zone=limit_qps burst=10 nodelay;
    limit_req_status 429;

    # Load list of IPs to blocklist
    include /etc/nginx/conf.d/blocklist_ips.conf;

    location / {
        proxy_pass http://{{ oomsm_backend_ipv4 }}:{{ oomsm_backend_port }};
    }

    {{ c.location_letsencrypt() }}


    location = /measurements {
        proxy_pass http://{{ oomsm_backend_ipv4 }}:{{ oomsm_backend_port }};

        proxy_cache apicache;
        proxy_cache_valid 200 1h;
        proxy_cache_lock on;
        proxy_cache_lock_timeout 58s;
        proxy_cache_lock_age 58s; # I don't quite understand the difference with proxy_cache_lock_timeout
        proxy_cache_use_stale error timeout invalid_header updating;
        proxy_cache_background_update on;
        add_header X-Cache-Status $upstream_cache_status;
    }

{% for handle in ["/", "/stats", "/api/_/global_overview", "/api/_/global_overview_by_month", "/api/_/measurement_count_by_country", "/api/_/runs_by_month", "/api/_/countries_by_month", "/api/_/asn_by_month"] %}
    location = {{ handle }} {
        proxy_pass http://{{ oomsm_backend_ipv4 }}:{{ oomsm_backend_port }};

        proxy_cache apicache;
        proxy_cache_valid 200 1h;
        proxy_cache_lock on;
        proxy_cache_lock_timeout 58s;
        proxy_cache_lock_age 58s; # I don't quite understand the difference with proxy_cache_lock_timeout
        proxy_cache_use_stale error timeout invalid_header updating;
        proxy_cache_background_update on;
        add_header X-Cache-Status $upstream_cache_status;
    }
{% endfor %}

# These caches are for the legacy OONI Explorer. We should drop them once the
# API endpoints are dropped.
{% for handle in ["/api/_/blockpages", "/api/_/blockpage_detected", "/api/_/blockpage_count"] %}
    location = {{ handle }} {
        proxy_pass http://{{ oomsm_backend_ipv4 }}:{{ oomsm_backend_port }};

        proxy_cache apicache;
        proxy_cache_valid 200 6h;
        proxy_cache_lock on;
        proxy_cache_lock_timeout 58s;
        proxy_cache_lock_age 58s;
        proxy_cache_use_stale error timeout invalid_header updating;
        proxy_cache_background_update on;
        add_header X-Cache-Status $upstream_cache_status;
    }
{% endfor %}

    # API v1 endpoints
    # These are the most popular, and heavy endpoints
{% for handle in ["/api/v1/version", "/api/v1/measurements"] %}
    location = {{ handle }} {
        proxy_pass http://{{ oomsm_backend_ipv4 }}:{{ oomsm_backend_port }};

        proxy_cache apicache;
        proxy_cache_valid 200 10m;
        add_header X-Cache-Status $upstream_cache_status;
    }
{% endfor %}

    location /metrics {
        #satisfy all;
        #allow {{ lookup('dig', 'prometheus.infra.ooni.io/A') }}/32;
        #deny all;

        proxy_pass http://{{ oomsm_backend_ipv4 }}:{{ oomsm_prometheus_port }};
        proxy_http_version 1.1;
    }
}
